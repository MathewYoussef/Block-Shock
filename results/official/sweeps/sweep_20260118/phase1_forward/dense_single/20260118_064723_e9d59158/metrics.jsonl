{"timestamp_unix": 1768718844.0737987, "run_id": "20260118_064723_e9d59158", "phase": "phase1_forward", "method": "dense_single", "N": 40960, "B": 64, "dtype": "bf16", "world_size": 2, "timings_ms": {"build": {"count": 0.0, "sum_ms": 0.0, "avg_ms": 0.0, "p50_ms": 0.0, "p95_ms": 0.0}, "forward": {"count": 100.0, "sum_ms": 582.6379218101501, "avg_ms": 5.8263792181015015, "p50_ms": 5.6422879695892325, "p95_ms": 6.431734299659729}, "backward": {"count": 0.0, "sum_ms": 0.0, "avg_ms": 0.0, "p50_ms": 0.0, "p95_ms": 0.0}, "opt_step": {"count": 0.0, "sum_ms": 0.0, "avg_ms": 0.0, "p50_ms": 0.0, "p95_ms": 0.0}, "compress": {"count": 0.0, "sum_ms": 0.0, "avg_ms": 0.0, "p50_ms": 0.0, "p95_ms": 0.0}, "allreduce": {"count": 0.0, "sum_ms": 0.0, "avg_ms": 0.0, "p50_ms": 0.0, "p95_ms": 0.0}, "total_step": {"count": 0.0, "sum_ms": 0.0, "avg_ms": 0.0, "p50_ms": 0.0, "p95_ms": 0.0}}, "memory_peak_bytes": 11749294080, "iterations": 100, "warmup_iters": 10, "weight_bytes_total": 3355443200, "weight_bytes_dense": 3355443200, "bias_bytes": 0}
